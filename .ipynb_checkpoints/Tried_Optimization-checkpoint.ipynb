{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c17e8086",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very Important to understand these\n",
    "\n",
    "# https://pypi.org/project/pyportfolioopt/\n",
    "# https://pyportfolioopt.readthedocs.io/en/latest/BlackLitterman.html\n",
    "# https://pyportfolioopt.readthedocs.io/en/latest/OtherOptimizers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c6be0",
   "metadata": {},
   "source": [
    "Here is an example on real life stock data, demonstrating how easy it is to find the long-only portfolio that maximises the Sharpe ratio (a measure of risk-adjusted returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38648b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "\n",
    "# Read in price data\n",
    "df = pd.read_csv(\"stock_prices.csv\", parse_dates=True, index_col=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b14fa611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GOOG</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>FB</th>\n",
       "      <th>BABA</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>GE</th>\n",
       "      <th>AMD</th>\n",
       "      <th>WMT</th>\n",
       "      <th>BAC</th>\n",
       "      <th>GM</th>\n",
       "      <th>T</th>\n",
       "      <th>UAA</th>\n",
       "      <th>SHLD</th>\n",
       "      <th>XOM</th>\n",
       "      <th>RRC</th>\n",
       "      <th>BBY</th>\n",
       "      <th>MA</th>\n",
       "      <th>PFE</th>\n",
       "      <th>JPM</th>\n",
       "      <th>SBUX</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.117203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.352438</td>\n",
       "      <td>3.9375</td>\n",
       "      <td>3.486070</td>\n",
       "      <td>1.752478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.365775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.766756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.166287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110818</td>\n",
       "      <td>1.827968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364733</td>\n",
       "      <td>4.1250</td>\n",
       "      <td>3.660858</td>\n",
       "      <td>1.766686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.398184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.766756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113209</td>\n",
       "      <td>1.835617</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124684</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.364050</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>3.660858</td>\n",
       "      <td>1.780897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.356516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.749088</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.194001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.113608</td>\n",
       "      <td>1.896803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362001</td>\n",
       "      <td>3.9375</td>\n",
       "      <td>3.641439</td>\n",
       "      <td>1.743005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.403821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.731422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.115402</td>\n",
       "      <td>1.904452</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.125516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.358586</td>\n",
       "      <td>3.8125</td>\n",
       "      <td>3.602595</td>\n",
       "      <td>1.705114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.287973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.722587</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.190537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>1.912100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            GOOG      AAPL  FB  BABA  AMZN        GE     AMD       WMT  \\\n",
       "date                                                                     \n",
       "1989-12-29   NaN  0.117203 NaN   NaN   NaN  0.352438  3.9375  3.486070   \n",
       "1990-01-02   NaN  0.123853 NaN   NaN   NaN  0.364733  4.1250  3.660858   \n",
       "1990-01-03   NaN  0.124684 NaN   NaN   NaN  0.364050  4.0000  3.660858   \n",
       "1990-01-04   NaN  0.125100 NaN   NaN   NaN  0.362001  3.9375  3.641439   \n",
       "1990-01-05   NaN  0.125516 NaN   NaN   NaN  0.358586  3.8125  3.602595   \n",
       "\n",
       "                 BAC  GM         T  UAA  SHLD       XOM  RRC       BBY  MA  \\\n",
       "date                                                                         \n",
       "1989-12-29  1.752478 NaN  2.365775  NaN   NaN  1.766756  NaN  0.166287 NaN   \n",
       "1990-01-02  1.766686 NaN  2.398184  NaN   NaN  1.766756  NaN  0.173216 NaN   \n",
       "1990-01-03  1.780897 NaN  2.356516  NaN   NaN  1.749088  NaN  0.194001 NaN   \n",
       "1990-01-04  1.743005 NaN  2.403821  NaN   NaN  1.731422  NaN  0.190537 NaN   \n",
       "1990-01-05  1.705114 NaN  2.287973  NaN   NaN  1.722587  NaN  0.190537 NaN   \n",
       "\n",
       "                 PFE       JPM  SBUX  \n",
       "date                                  \n",
       "1989-12-29  0.110818  1.827968   NaN  \n",
       "1990-01-02  0.113209  1.835617   NaN  \n",
       "1990-01-03  0.113608  1.896803   NaN  \n",
       "1990-01-04  0.115402  1.904452   NaN  \n",
       "1990-01-05  0.114405  1.912100   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44242b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#expected_returns()\n",
    "# By convention, the output of these methods is expected *annual* returns. It is assumed that\n",
    "# *daily* prices are provided, though in reality the functions are agnostic\n",
    "# to the time period (just change the ``frequency`` parameter). Asset prices must be given as\n",
    "# a pandas dataframe, as per the format described in the :ref:`user-guide`.\n",
    "# All of the functions process the price data into percentage returns data, before\n",
    "# calculating their respective estimates of expected returns.\n",
    "\n",
    "# Currently implemented:\n",
    "\n",
    "#     - general return model function, allowing you to run any return model from one function.\n",
    "#     - mean historical return\n",
    "#     - exponentially weighted mean historical return\n",
    "#     - CAPM estimate of returns\n",
    "\n",
    "# Additionally, we provide utility functions to convert from returns to prices and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219c4324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# risk_models()\n",
    "# The ``risk_models`` module provides functions for estimating the covariance matrix given\n",
    "# historical returns.\n",
    "\n",
    "# The format of the data input is the same as that in :ref:`expected-returns`.\n",
    "\n",
    "# **Currently implemented:**\n",
    "\n",
    "# - fix non-positive semidefinite matrices\n",
    "# - general risk matrix function, allowing you to run any risk model from one function.\n",
    "# - sample covariance\n",
    "# - semicovariance\n",
    "# - exponentially weighted covariance\n",
    "# - minimum covariance determinant\n",
    "# - shrunk covariance matrices:\n",
    "\n",
    "#     - manual shrinkage\n",
    "#     - Ledoit Wolf shrinkage\n",
    "#     - Oracle Approximating shrinkage\n",
    "\n",
    "# - covariance to correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119a7b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected returns and sample covariance\n",
    "mu = expected_returns.mean_historical_return(df)\n",
    "S = risk_models.sample_cov(df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb7f169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('GOOG', 0.0458), ('AAPL', 0.06743), ('FB', 0.2008), ('BABA', 0.08494), ('AMZN', 0.03525), ('GE', 0.0), ('AMD', 0.0), ('WMT', 0.0), ('BAC', 0.0), ('GM', 0.0), ('T', 0.0), ('UAA', 0.0), ('SHLD', 0.0), ('XOM', 0.0), ('RRC', 0.0), ('BBY', 0.01587), ('MA', 0.3287), ('PFE', 0.20394), ('JPM', 0.0), ('SBUX', 0.01726)])\n",
      "Expected annual return: 29.9%\n",
      "Annual volatility: 21.8%\n",
      "Sharpe Ratio: 1.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(0.2994470916123031),\n",
       " np.float64(0.2176433168139341),\n",
       " np.float64(1.375861643701672))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize for maximal Sharpe ratio\n",
    "ef = EfficientFrontier(mu, S)\n",
    "raw_weights = ef.max_sharpe() #optimizes for maximal Sharpe ratio (a.k.a the tangency portfolio), check other options in EfficientFrontier()\n",
    "cleaned_weights = ef.clean_weights() #rounds the weights and clips near-zeros.\n",
    "ef.save_weights_to_file(\"weights.csv\")  # saves to file\n",
    "print(cleaned_weights)\n",
    "ef.portfolio_performance(verbose=True) #calculates the expected return, volatility and Sharpe ratio for the optimized portfolio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4cf5f7",
   "metadata": {},
   "source": [
    "This is interesting but not useful in itself. However, PyPortfolioOpt provides a method which allows you to convert the above continuous weights to an actual allocation that you could buy. Just enter the most recent prices, and the desired portfolio size ($10,000 in this example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "529d2c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete allocation: {'MA': 19, 'PFE': 57, 'FB': 12, 'BABA': 4, 'AAPL': 4, 'GOOG': 1, 'SBUX': 2, 'BBY': 2}\n",
      "Funds remaining: $17.46\n"
     ]
    }
   ],
   "source": [
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n",
    "\n",
    "\n",
    "latest_prices = get_latest_prices(df)\n",
    "\n",
    "da = DiscreteAllocation(cleaned_weights, latest_prices, total_portfolio_value=10000)\n",
    "allocation, leftover = da.greedy_portfolio()\n",
    "print(\"Discrete allocation:\", allocation)\n",
    "print(\"Funds remaining: ${:.2f}\".format(leftover))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f94b9",
   "metadata": {},
   "source": [
    "Adding constraints or different objectives\n",
    "\n",
    "    Long/short: by default all of the mean-variance optimization methods in PyPortfolioOpt are long-only, but they can be initialised to allow for short positions by changing the weight bounds:\n",
    "\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(-1, 1))\n",
    "\n",
    "    Market neutrality: for the efficient_risk and efficient_return methods, PyPortfolioOpt provides an option to form a market-neutral portfolio (i.e weights sum to zero). This is not possible for the max Sharpe portfolio and the min volatility portfolio because in those cases because they are not invariant with respect to leverage. Market neutrality requires negative weights:\n",
    "\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(-1, 1))\n",
    "ef.efficient_return(target_return=0.2, market_neutral=True)\n",
    "\n",
    "    Minimum/maximum position size: it may be the case that you want no security to form more than 10% of your portfolio. This is easy to encode:\n",
    "\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(0, 0.1))\n",
    "\n",
    "One issue with mean-variance optimization is that it leads to many zero-weights. While these are \"optimal\" in-sample, there is a large body of research showing that this characteristic leads mean-variance portfolios to underperform out-of-sample. To that end, I have introduced an objective function that can reduce the number of negligible weights for any of the objective functions. Essentially, it adds a penalty (parameterised by gamma) on small weights, with a term that looks just like L2 regularisation in machine learning. It may be necessary to try several gamma values to achieve the desired number of non-negligible weights. For the test portfolio of 20 securities, gamma ~ 1 is sufficient\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.add_objective(objective_functions.L2_reg, gamma=1)\n",
    "ef.max_sharpe()\n",
    "\n",
    "Black-Litterman allocation\n",
    "\n",
    "As of v0.5.0, we now support Black-Litterman asset allocation, which allows you to combine a prior estimate of returns (e.g the market-implied returns) with your own views to form a posterior estimate. This results in much better estimates of expected returns than just using the mean historical return. Check out the docs for a discussion of the theory, as well as advice on formatting inputs.\n",
    "\n",
    "S = risk_models.sample_cov(df)\n",
    "viewdict = {\"AAPL\": 0.20, \"BBY\": -0.30, \"BAC\": 0, \"SBUX\": -0.2, \"T\": 0.131321}\n",
    "bl = BlackLittermanModel(S, pi=\"equal\", absolute_views=viewdict, omega=\"default\")\n",
    "rets = bl.bl_returns()\n",
    "\n",
    "ef = EfficientFrontier(rets, S)\n",
    "ef.max_sharpe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f84e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9462c186",
   "metadata": {},
   "source": [
    "Adding constraints or different objectives\n",
    "\n",
    "    Long/short: by default all of the mean-variance optimization methods in PyPortfolioOpt are long-only, but they can be initialised to allow for short positions by changing the weight bounds:\n",
    "\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(-1, 1))\n",
    "\n",
    "    Market neutrality: for the efficient_risk and efficient_return methods, PyPortfolioOpt provides an option to form a market-neutral portfolio (i.e weights sum to zero). This is not possible for the max Sharpe portfolio and the min volatility portfolio because in those cases because they are not invariant with respect to leverage. Market neutrality requires negative weights:\n",
    "\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(-1, 1))\n",
    "ef.efficient_return(target_return=0.2, market_neutral=True)\n",
    "\n",
    "    Minimum/maximum position size: it may be the case that you want no security to form more than 10% of your portfolio. This is easy to encode:\n",
    "\n",
    "ef = EfficientFrontier(mu, S, weight_bounds=(0, 0.1))\n",
    "\n",
    "One issue with mean-variance optimization is that it leads to many zero-weights. While these are \"optimal\" in-sample, there is a large body of research showing that this characteristic leads mean-variance portfolios to underperform out-of-sample. To that end, I have introduced an objective function that can reduce the number of negligible weights for any of the objective functions. Essentially, it adds a penalty (parameterised by gamma) on small weights, with a term that looks just like L2 regularisation in machine learning. It may be necessary to try several gamma values to achieve the desired number of non-negligible weights. For the test portfolio of 20 securities, gamma ~ 1 is sufficient\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.add_objective(objective_functions.L2_reg, gamma=1)\n",
    "ef.max_sharpe()\n",
    "\n",
    "Black-Litterman allocation\n",
    "\n",
    "As of v0.5.0, we now support Black-Litterman asset allocation, which allows you to combine a prior estimate of returns (e.g the market-implied returns) with your own views to form a posterior estimate. This results in much better estimates of expected returns than just using the mean historical return. Check out the docs for a discussion of the theory, as well as advice on formatting inputs.\n",
    "\n",
    "S = risk_models.sample_cov(df)\n",
    "viewdict = {\"AAPL\": 0.20, \"BBY\": -0.30, \"BAC\": 0, \"SBUX\": -0.2, \"T\": 0.131321}\n",
    "bl = BlackLittermanModel(S, pi=\"equal\", absolute_views=viewdict, omega=\"default\")\n",
    "rets = bl.bl_returns()\n",
    "\n",
    "ef = EfficientFrontier(rets, S)\n",
    "ef.max_sharpe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86b816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_zipline",
   "language": "python",
   "name": "env_zipline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
